# Income Spending Survey Tool

This project is a simple survey tool designed to collect and analyze participants' income and spending data. It includes a Flask web application for data collection, MongoDB for data storage, a Python class for data processing, and a Jupyter Notebook for data analysis and visualization.

## Project Structure

```
foster/
├── app.py                   # Flask application (collects and stores data in MongoDB)
├── user_processor.py        # Python class (User) to fetch data from MongoDB and save as CSV
├── templates/
│   └── index.html           # HTML template for the survey form
├── static/
│   └── style.css            # Basic CSS for the survey form
├── analysis.ipynb           # Jupyter notebook for data analysis and visualization
├── charts/                  # Directory to store exported charts from the notebook
├── survey_data.csv          # CSV file generated by user_processor.py (contains survey data)
├── requirements.txt         # Python dependencies for the project
└── README.md                # This file
```

## Prerequisites

*   Python 3.7+
*   MongoDB installed and running (default connection: `mongodb://localhost:27017/`)
*   Access to a terminal or command prompt

## Setup and Usage

### Option 1: Running Locally (without Docker)

1.  **Clone the Repository (or create files as listed above):**
    If this were a git repository, you'd clone it. For now, ensure all files are in the structure shown above.

2.  **Create a Virtual Environment (Recommended):**
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```

3.  **Install Dependencies:**
    Navigate to the project root directory (`foster/`) in your terminal and run:
    ```bash
    pip install -r requirements.txt
    ```

4.  **Ensure MongoDB is Running:**
    Start your MongoDB server if it's not already running. The application expects MongoDB to be accessible at `mongodb://localhost:27017/`. If your MongoDB instance is different, you will need to update the connection string in `app.py` (variable `client`) and `user_processor.py` (in the `User` class constructor).

5.  **Run the Flask Web Application:**
    Execute the `app.py` script to start the survey application:
    ```bash
    python app.py
    ```
    The application will typically be available at `http://127.0.0.1:5000/` in your web browser.

6.  **Submit Survey Data:**
    Open the web application in your browser and submit a few sample survey responses. This data will be stored in the `survey_db` database under the `user_data` collection in MongoDB.

7.  **Process Data and Generate CSV:**
    After submitting some data, run the `user_processor.py` script to fetch the data from MongoDB and save it as `survey_data.csv` in the project root:
    ```bash
    python user_processor.py
    ```
    This will create or update the `survey_data.csv` file.

8.  **Perform Data Analysis in Jupyter Notebook:**
    *   Start the Jupyter Notebook server:
        ```bash
        jupyter notebook
        ```
    *   Open `analysis.ipynb` from the Jupyter interface in your browser.
    *   Run the cells in the notebook to load the `survey_data.csv`, perform analysis, and generate visualizations.
    *   The generated charts (`ages_highest_income.png` and `gender_spending_distribution.png`) will be saved in the `charts/` directory.

### Option 2: Running with Docker Compose (Recommended for Containerized Environment)

This method uses Docker to containerize the Flask application and MongoDB, making it easy to manage and deploy.

**Prerequisites for Docker:**
*   Docker Desktop (or Docker Engine and Docker Compose CLI) installed and running.

**Steps:**

1.  **Clone the Repository (or ensure all files are present):**
    Make sure you have `Dockerfile`, `docker-compose.yml`, and all other project files.

2.  **Build and Run the Application using Docker Compose:**
    Navigate to the project root directory (`foster/`) in your terminal and run:
    ```bash
    docker-compose up --build
    ```
    *   `--build` forces Docker to rebuild the image if there are changes to `Dockerfile` or application code.
    *   This command will: 
        *   Build the Docker image for the Flask application based on the `Dockerfile`.
        *   Pull the official MongoDB image.
        *   Start containers for both the web application and the MongoDB database.
        *   The Flask application will be accessible at `http://localhost:5001` (port changed from 5000 to avoid conflicts).
        *   MongoDB will be accessible on its standard port `27017` from within the Docker network (and mapped to the host).

3.  **Submit Survey Data:**
    Open `http://localhost:5001/` in your web browser and submit survey responses. The data will be stored in the MongoDB container.

4.  **Process Data and Generate CSV:**
    Since `user_processor.py` is also part of the webapp container and configured to use the same `MONGO_URI` environment variable, you can run it inside the running `webapp` container.
    *   First, find the container ID or name for the `webapp` service:
        ```bash
        docker-compose ps
        ```
        Look for the entry for `foster_webapp_1` or similar.
    *   Then, execute the script inside the container:
        ```bash
        docker-compose exec webapp python user_processor.py
        ```
        Alternatively, if your `docker-compose.yml` names the service `webapp` (as in the example), you can often use the service name directly:
        ```bash
        docker exec -it <container_name_or_id_for_webapp> python user_processor.py 
        ```
        (You might need to find the specific container name using `docker ps` if the above `docker-compose exec` doesn't work as expected for your setup).
        This will create/update `survey_data.csv` inside the container, and because of the volume mount (`.:/app`), it will also appear in your local project directory.

5.  **Perform Data Analysis in Jupyter Notebook (Run Locally):**
    *   Ensure you have Jupyter installed in your local environment (or a separate Python environment for analysis):
        ```bash
        pip install jupyter pandas matplotlib seaborn
        ```
    *   Start the Jupyter Notebook server from your project directory:
        ```bash
        jupyter notebook
        ```
    *   Open `analysis.ipynb`. It will read `survey_data.csv` (which was created by the script running in the Docker container but accessible locally due to the volume mount).
    *   Run the cells to generate charts, which will be saved to the local `charts/` directory.

6.  **Stopping the Application:**
    To stop the Docker Compose services, press `Ctrl+C` in the terminal where `docker-compose up` is running, or run:
    ```bash
    docker-compose down
    ```
    To remove the persistent MongoDB volume (and all data stored in it), run:
    ```bash
    docker-compose down -v
    ```

## Code Explanation

*   **`Dockerfile`**:
    *   Defines the environment for the Flask application container.
    *   Starts from a Python 3.9 slim base image.
    *   Sets the working directory to `/app`.
    *   Copies `requirements.txt` and installs dependencies.
    *   Copies the rest of the application code.
    *   Exposes port 5000.
    *   Sets environment variables `FLASK_APP` and `FLASK_RUN_HOST`.
    *   The default command is `flask run` to start the development server.

*   **`docker-compose.yml`**:
    *   Defines and manages multi-container Docker applications.
    *   `version: '3.8'`: Specifies the Docker Compose file format version.
    *   `services`:
        *   `webapp`:
            *   `build: .`: Builds the image from the `Dockerfile` in the current directory.
            *   `ports: - "5001:5000"`: Maps port 5000 of the container to port 5001 on the host.
            *   `volumes: - .:/app`: Mounts the current project directory on the host to `/app` in the container. This allows for live code reloading during development without rebuilding the image.
            *   `depends_on: - mongo`: Ensures the `mongo` service starts before the `webapp` service.
            *   `environment: - MONGO_URI=mongodb://mongo:27017/survey_db`: Sets the MongoDB connection string. `mongo` is the hostname of the MongoDB service within the Docker network. `- FLASK_DEBUG=1` enables Flask debug mode.
        *   `mongo`:
            *   `image: mongo:latest`: Uses the latest official MongoDB image from Docker Hub.
            *   `ports: - "27017:27017"`: Maps port 27017 of the container to port 27017 on the host (optional, but useful for direct database access if needed).
            *   `volumes: - mongo-data:/data/db`: Creates a named volume `mongo-data` to persist MongoDB data even if the container is stopped or removed.
    *   `volumes: mongo-data:`: Declares the named volume.

*   **`app.py` (Changes for Docker)**:
    *   Imports `os`.
    *   Retrieves the MongoDB connection URI from the `MONGO_URI` environment variable. If not set, it defaults to `mongodb://localhost:27017/survey_db` (suitable for local non-Docker execution or if `MONGO_URI` isn't passed for some reason).
    *   The database name is now parsed from the URI, with a fallback to `survey_db`.

*   **`user_processor.py` (Changes for Docker)**:
    *   Imports `os`.
    *   The constructor now accepts an optional `mongo_uri`. If not provided, it checks the `MONGO_URI` environment variable.
    *   If `MONGO_URI` is also not found, it defaults to `mongodb://localhost:27017/survey_db`.
    *   The database name is parsed from the URI, or falls back to the `db_name` parameter or a parsed default.

*   **`templates/index.html`**:
    *   A standard HTML form for users to input their data.
    *   Includes fields for age, gender (dropdown), total income.
    *   Uses checkboxes for expense categories. If a category is relevant, the user can check it and enter the corresponding amount in a textbox.
    *   Links to `static/style.css` for basic styling.

*   **`static/style.css`**:
    *   Provides minimal CSS to improve the appearance of the survey form.

*   **`analysis.ipynb`**:
    *   A Jupyter Notebook for analyzing the data from `survey_data.csv`.
    *   **Imports**: `pandas` for data manipulation, `matplotlib.pyplot` and `seaborn` for plotting, and `os` for path operations.
    *   **Load Data**: Reads the `survey_data.csv` into a Pandas DataFrame.
    *   **Data Cleaning (Basic)**: Includes an example of converting columns to numeric types and filling `NaN` values in expense columns with `0` (assuming no entry means zero expense for that category).
    *   **Visualization 1 (Ages with Highest Income)**:
        *   Groups the data by `age` and calculates the mean `total_income`.
        *   Sorts the results to find the top ages with the highest average income.
        *   Creates a bar plot showing this information.
        *   Saves the plot as `charts/ages_highest_income.png`.
    *   **Visualization 2 (Gender Distribution Across Spending Categories)**:
        *   Reshapes (melts) the DataFrame to have expense categories and their amounts in a long format, suitable for grouped bar plots by gender.
        *   Groups by `gender` and `expense_category` to sum the `amount_spent`.
        *   Creates a grouped bar plot showing spending in each category, broken down by gender.
        *   Saves the plot as `charts/gender_spending_distribution.png`.
    *   **Exporting Charts**: Notes that charts are saved during their generation steps.

*   **`requirements.txt`**:
    *   Lists the Python packages required to run the project: `flask`, `pymongo`, `pandas`, `matplotlib`, `seaborn`, and `jupyter`.

*   **`charts/` (Directory)**:
    *   This directory is created by the `analysis.ipynb` notebook (if it doesn't exist) to store the exported `.png` image files of the generated charts.

This setup provides a basic framework for survey data collection, storage, processing, and analysis as per the requirements (excluding AWS deployment).

It can now be run either locally or using Docker Compose for a containerized environment. 